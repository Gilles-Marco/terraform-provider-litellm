---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "litellm_model Resource - terraform-provider-litellm"
subcategory: "LLM Model Management"
description: |-
The `litellm_model` resource allows you to manage AI language models within your LiteLLM Proxy instance using Terraform.
This resource enables you to automate the creation, updating, and deletion of models, integrating AI model lifecycle
management into your infrastructure as code practices.

By using `litellm_model`, you can seamlessly incorporate AI capabilities into your applications and services, while
maintaining consistency and version control through Terraform's declarative configurations.

---

# litellm_model (Resource)

## Example Usage

```terraform
resource "litellm_model" "example" {
  model_name = "example-model"

  litellm_params = {
    custom_llm_provider = "openai"
    model               = "gpt-3.5-turbo"
    api_key             = "your_underlying_model_api_key"
    api_base            = "https://api.openai.com/v1"
  }

  model_info = {
    id         = "unique-model-id"
    base_model = "gpt-3.5-turbo"
    tier       = "paid"
  }
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `litellm_params` (Map of String) Parameters for the model as per LiteLLM API.
- `model_name` (String) Name of the model to be managed.

### Optional

- `model_info` (Map of String) Additional model information.

### Read-Only

- `id` (String) The ID of the model.

## Import

Import is supported using the following syntax:

```shell
#!/bin/sh
terraform import litellm_model.example_model existing-model-name
```
